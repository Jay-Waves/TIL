在学习指令集和设计简单CPU的时候，总是认为指令给出的地址就是指令、数据的内存地址，但在现代的高性能处理器中，事实不是这样。

现代的高性能处理器使用虚拟存储器，虚拟存储器使用“虚拟地址”，而非“物理地址”，那么什么是虚拟地址，为什么要有虚拟地址，虚拟地址是如何工作的？

> 作者是: 加一茶匙快乐 [计算机体系结构-虚拟存储器 - 知乎](https://zhuanlan.zhihu.com/p/570527388)

## 1、虚拟内存和MMU

在早期，计算机程序规模很小，程序在运行的时候可以一次性全部存入内存，但是随着程序规模增大，物理内存已经无法容纳下全部程序，**因此人们想要找到一个用小内存支持大程序的方法**。注意，这里的程序规模指的是**程序的地址空间大小**，一个32位机器上的程序，其程序规模就是2^{32}个字节。

程序比内存大意味着什么？对于一个256MB的内存，如果程序出现地址256M，那么内存芯片就会出错，因为内存的地址范围是\[0~256M-1\]，地址256M超出了内存所能容纳的地址范围，是一个非法的地址。出现这种问题的原因在于我们总想着程序的指令和数据可以全部存在内存上，因此总是试图用指令给出的地址直接和内存交流。为了规避这个问题，为了用较小的内存支持较大的程序，人们提出虚拟存储器的概念。

虚拟存储器是一种抽象，指的是程序员假想出一个大小有程序地址空间那么大的内存给自己使用，但实际上他只拥有一个小得多的内存。就好像为32位机器编程的程序员以为自己有一个4GB大小的内存，但实际上他可能只有一个256MB的内存。

要使用虚拟存储器，就不能用指令给出的地址直接和内存沟通，因为程序给出的地址的位数显著多于内存芯片的地址位数**。在虚拟存储器中要使用“虚拟地址”。首先，指令给出虚拟地址，然后虚拟地址会被送往一个被称为“[内存管理](Linux/Concepts/内存管理.md)单元”（即MMU）的地方，在MMU中虚拟地址会被转换为内存芯片能理解的物理地址。**

![](https://pic3.zhimg.com/v2-245ba6ef68373949c483b605ba46838e_b.jpg)

图一：不使用MMU，CPU直接送物理地址到内存

图一是不使用虚拟存储器的系统架构，CPU的PC和数据地址会**直接**送给物理存储器；图二是使用虚拟存储器的系统架构，CPU的PC和数据虚拟地址会首先送往MMU，MMU把转换得到的物理地址送给物理存储器。

![](https://pic2.zhimg.com/v2-6dbef16618a28e3eb11996193330f179_b.jpg)

图二：使用MMU，MMU将虚拟地址转换成物理地址，然后送往内存

## 2、地址转换

接下来将以“**请求式分页虚拟存储器”**为例，讲解虚拟地址和MMU的工作过程。

请求式分页虚拟存储器把程序的地址空间**按“页”划分**，其典型值是4KB，在一个16位机器中，如果按4KB的页去划分地址空间，一个程序应该对应2^16/(2^12)=16页。这16页会首先存放在外存（如磁盘）中，在磁盘里面，磁盘的存储空间也按照“页”划分，在磁盘里这种存储单元被称为盘块，盘块的大小和页一样，可以说盘块就是磁盘中的页。

当程序开始运行（为简单起见，这里讲的是单程序操作系统，没有多程序并发），操作系统首先从磁盘上调取少量必须的盘块进入内存，CPU拿着这些盘块/页运行程序。假设内存只有8个页大小，即只有32KB大小，那么操作系统一开始就调取8页进入内存，注意，内存的存储空间也按页大小进行划分，划分出和页一样大的存储单元“页框”，8个页就被放进8个页框中。

**为了正确解读程序给出的虚拟地址，系统会维护一个映射表**，映射表记录了内存中8个页框各自对应程序地址空间的哪一页。举个例子，当程序要查找第2页，它只会给出第2页的地址（逻辑地址4K~8K-1），而此时第2页未必就在内存中第2个页框中，如果第1页没有调入内存，此时第2页就可能在内存的第1个页框中，因此映射表要记录这个信息，当程序要查询第2页，MMU就根据映射表把地址（逻辑地址4K~8K-1）转换成第1个页框的地址（物理地址0~4K-1）。

**下面用一张图进一步举例说明，在图三中**，程序地址空间被分为8页，而内存只有4个页大小，因此程序运行时内存只能保存4页，其余4页在磁盘中，图中磁盘处是省略画法。

当指令给出虚拟地址2K，MMU会根据映射表（形如图三中左边的表格）了解到2K地址对应的第零页在内存中被放在第二个页框中，因此MMU会把虚拟地址2K转换成2K+8K=10K，此时CPU用10K去查找内存就可以找到对应的指令/数据。

![](https://pic1.zhimg.com/v2-ec144e865073742c09202d3f1580e510_b.jpg)

图三：使用内存中映射表记录地址映射关系

当CPU给出地址为5K时，MMU根据映射表发现5K地址对应的第一页不在物理内存中（在映射表中这个信息由一个“有效位”给出），此时CPU会产生**内部异常“缺页中断”**，操作系统会执行缺页中断的处理程序。程序会把在磁盘中的第一页调入到内存，如果内存有空闲页框，则直接调入；如果内存已经满了，就根据调换算法选出一页调出内存，如果该页被修改过，则要把页内容写回磁盘，如果没修改过，就简单地把映射表中的有效位置为无效即可。

## 3、单级页表

前文反复提到映射表这个概念，**其实映射表就是页表**，页表就是记录虚拟地址和物理地址映射关系的一张表格，更进一步，**页表是记录虚拟页号和物理页框号映射关系的表格**。

**这张表格是一张顺序表**，它很大，存储了地址空间中每一页的映射关系，在32位机器中，假设每页4KB，那么程序的总大小就有就有2^{32}/(4K)=2^{20}页，也就是1M页，因此页表要记录1M项映射关系。

每项记录具体有什么内容？首先想到可能要包含虚拟页号，在32位字节编址的机器中，一页4KB，页内偏移（用于在页内寻址字节）需要用4K=12位来记录，于是其余的高20位就是所谓的“虚拟页号”。但是，虚拟页号实际上是不用保存的，因为页表是一张顺序表，虚拟页号的信息实际上包含在顺序表的下标之中，换个说法，虚拟页号实际上是用来计算顺序表元素的位置的，因此页表里面不需要记录虚拟页号；另外，页内偏移也不用保存，因为页框和页一样大，页内偏移可以直接用在物理地址中；

**页表项不包括虚拟页号，但一定要包含物理页框号**，物理页框号的位数视物理内存的大小而定。32位机器对应虚拟地址有4GB，但内存可能只有1GB，此时物理页框号的最大值就应当是2^{19}-1，而虚拟页号的最大值是2^{21}-1。在这个情况下，物理页框号需要18位。

**然后还要包含有效位**，正如图三的例子，有些页在执行程序的时候可能不在内存里，但是这些页肯定要在页表中存有记录（为什么？页表是顺序表，即使有的页不存在映射关系，也必须在连续空间内占据属于自己的位置），因此必须要用“有效位”来标记某些记录是否有效。

**最后是“脏”位**，有的页被调入内存后被CPU修改过，此时如果需要调换这一页，就要根据“脏”位判断是否要把该页写回磁盘；如果一个页需要被替换，但是其不脏，那么就不需要把它写回磁盘。

把以上的数据汇总如图四，页表中每一项都需要18+1+1=20位，32位机器中数据总是以32位长度存取，因此可以用4B来存储页表中的一项纪录，此时页表就要占用4B\*1M=4MB的存储空间，这非常大。

![](https://pic2.zhimg.com/v2-893731deb84d06c153f29f4b57ab8b45_b.jpg)

图四：页表项，包括物理内存地址、有效位和脏位

一个程序的页表需要占用4MB连续的存储空间，这肯定不能用CPU内寄存器存储，**因此页表是存储在内存一片连续空间内的**。MMU进行地址转换的时候需要查询页表，那么MMU是如何知道页表的物理地址的呢？这是由CPU内一个叫做**“页表寄存器”**的寄存器完成的，该寄存器记录了页表的起始地址，根据页表的起始地址和页号，MMU就可以以随机存取的方式读取页表的任一记录。

现在再来整理思路，CPU在执行指令的时候首先给出虚拟地址，CPU内MMU根据虚拟地址和页表寄存器查询存放在内存中的页表，根据查询到的记录得到物理页框号，此时MMU再用物理页框号和虚拟地址的页内偏移字段组合起来查询内存中数据。注意，如果页不在内存中，就会触发缺页中断，缺页中断需要调用磁盘，因此需要花费很多时间。

可以看到在这个过程中，**一次内存数据的访问实际上对应两次内存访问**，第一次访问的是页表，第二次访问的才是页的内容，如果发生缺页，则还需要访问磁盘。

页表对于一个程序而言非常重要，如果读者对操作系统有了解，就知道CPU在切换进程的时候需要**保存进程现场和恢复进程现场**，而所谓的“现场”就是由PC、通用寄存器和页表等内容组成。

## 4、多级页表

单级页表虽然实现了地址转换，但是单级页表需要为每一个程序分配4MB的连续内存空间，在多程序并发的操作系统中，数十个乃至数百个单级页表会让内存苦不堪言——不仅因为这些页表会占用大量内存空间，**而且其要求分配的内存是“连续的”**，这相当于是要求内存为其分配连续的十个页框。

与此同时，大部分程序其实根本用不到那么多页，没有多少程序真的需要用完4GB的虚拟地址空间，**因此页表中的绝大多数记录都是无效的，实际上并没有被使用**，这样一来内存的使用效率就降低了。

为了解决单级页表效率低的问题，多级页表被提了出来。

还记得为什么要用虚拟存储器吗？一个程序正常来说需要占据4GB内存，但是在使用虚拟存储器之后，内存可以用很小的容量支持这些程序，我们是如何做到这一点的？我们通过使用单级页表记录页的映射关系节约了大量的存储空间。如果一个页没有被使用，换句话说，如果有一段地址根本没有被使用过，其对应的页就不会真的存在在内存中，这一个信息被页表中的“有效位”记录，**如果有效位标志为无效，就说明该页不存在与物理内存的映射关系，其也就不存在在内存中**，这样就节约了内存空间。

现在我们要用同样的思想来节约页表的空间——如果有的页表记录根本就没有用，那么就不应该让它占据内存空间。

如果以4KB大小把单级页表的连续4MB划分开，或者说把1M项页表项划分成1K份，那么单级页表就被划分成1K个子块，每个子块的大小正好是一页。此时我们用一张顺序表记录这1K个子块的物理内存首地址，那么就可以像单级页表节约内存一样节约页表。

再进一步，**如果用一整页来当作1K个子页表的索引表，那么在索引表中记录有效的子页表才该真实存在，别的记录无效的子页表实际上没有被程序使用，因此就不应该真实存在**。通过这样的做法，我们成功节约了页表的空间，而且不再需要页表占用连续的内存空间。

整理上面的脉络不难得出一个结论，那就是所谓的子页表的索引表其实就是子页表的页表，我们把这里面的子页表称作第二级页表，把索引表称为第一级页表。

让我们用图来解说这个过程，在图五中第一级页表和每一张第二级页表都恰好占据一页，即4KB，因此第一级页表包含1K个记录，其中每个记录都记录一张第二级页表在内存中的首地址，每张第二级页表也包含1K个记录，其中记录了虚拟页号和物理页框号的映射关系。

![](https://pic4.zhimg.com/v2-5efc1b87cfcb9097faaaf9394c0bd7a7_b.jpg)

图五：二级页表，第一级页表记录第二级页表的内存地址

假如此时第一级页表中的第1项记录无效，那就说明第1张第二级页表实际上不存在，那么我们就可以节省下一张第二级页表的存储空间，即省下了4KB，在很多程序中，第一级页表里的大部分记录都是无效的，因此我们省下了海量的内存空间。与此同时，第二级页表不再需要彼此连续，这样就让操作系统在分配内存的时候变得更灵活。

上面简单说明了二级页表的提出背景和原理，下面具体说说在二级页表下CPU该如何访问内存。

正如在单级页表下CPU把地址划分成虚拟页号和页内偏移两段，**在二级页表下CPU要把地址划分成虚拟一级页号、虚拟二级页号和页内偏移三段**，这三段分别占据32为地址的高中低三段。

进一步说，一级页表占据一页，包含1K个记录，因此需要10位地址来寻址；二级每个页表占据一页，包含1K个记录，因此也需要10位地址来寻址；根据物理内存地址寻址到每一页都是4KB大小，因此需要12位页内偏移地址来寻址。

到这里，CPU的访问过程就呼之欲出了，CPU访问数据时首先根据**第一级页表寄存器**（记录第一级页表的物理内存首地址）和第一级虚拟页号查找第一级页表，然后根据第一级页表给出的物理内存地址和第二级虚拟页号查找第二级页表，然后根据第二级页表给出的物理内存地址和页内偏移查找内存中的数据。

在程序刚开始运行时，操作系统只会为程序分配第一级页表，当CPU开始寻址，操作系统就要逐步分配第二级页表，并修改第一级页表中的相关记录。每当第一级虚拟页号发生变化，就说明CPU要求访问一个新的第二级页表，此时操作系统要分配第二级页表。

假想一个理想场景，一个程序从头到尾只使用高10位地址为0的虚拟地址，即第一级虚拟页号固定为0，那么该程序就只需要一个第二级页表，这样一来我们就节省了其余第二级页表的空间。

**在二级页表中，CPU要访问一次内存中的数据，实际上对应三次内存访问**，第一次访问的是一级页表，第二次访问的是二级页表，第三次访问的才是真正的数据，由此看到二级页表让单次数据访问变得更加慢了，但是这为我们节省了内存空间。

在二级页表之上还可以建立页表，即多级页表，为什么又要建立更高级的页表？因为如果把最低级的子页表划分得更小，那么上级页表的记录就更多，如果上级页表的大小超过一页，那么就可以考虑用更高级的页表来节省中间级页表的空间，但与此同时CPU访问内存的速度将会进一步降低。**我们应该力图让最高级的页表的大小小于一页**，这样CPU在第一次访问内存的时候才能立刻得到子页表的地址。

## 5、虚拟存储器的优点

讲解了这么多页式存储的原理，现在总结一下虚拟存储器的优点。

首先，虚拟存储器是为了解决程序太大而内存太小的问题而提出的，它依靠建立索引表的方式节约了实际上没有使用的地址空间，让小内存支持了大程序；

其次，每个程序在虚拟存储器中都认为自己拥有全部地址空间，这样就不需要在程序编写的时候人为限制编址范围；

再有，引入虚拟地址到物理地址的映射，为内存管理带来便利，操作系统可以更灵活地为程序分配内存空间，如程序申请（malloc）超过一页的连续空间时，操作系统可以通过映射把它们分配到离散的空间中，这样的做法极大地提高了内存的利用率。

## 6、页缺失（Page Fault）

CPU在访问页表时可能发现要查找的页不在物理内存中，此时就要调用“**缺页中断处理程序”**处理缺页，中断程序要访问磁盘，把磁盘中对应的盘块写到内存中，如果内存有空闲页则写进空闲页，如果没有空闲页则替换某一页，如果替换页被修改过，需要把替换页写回到磁盘。在把盘块调入内存之后还要修改页表。

请注意，这里有个问题，**操作系统怎么知道需要调入哪个盘块**？其实操作系统在程序运行的一开始会在磁盘中为程序开辟一个swap区，swap区内存放着程序所有的页，然后操作系统会在内存中用一个表格来记录程序每个页和swap区的映射关系，当要调入盘块，就先查询内存中的映射表获得盘块号，然后根据盘块号调用磁盘。

在单级页表机制下这个“页和swap区的映射关系”可以写进页表中，但是在多级页表机制下必须要用单独的表格，因为多级页表不会为每个页都建立页表项，但是“页和swap的映射关系”必须全部记录，当CPU发现缺页，它必须要可以得到缺失的页在磁盘中的位置。

## 7、TLB

到目前为止，多级页表机制下CPU访问一次数据需要进行多次内存访问，这个速度是极慢的，因此要想办法加快这个过程。就像用cache缓存指令和数据一样，我们可以基于**局部性原理**在CPU内保存页表项的副本，这个用于保存副本的缓存就是**TLB（Translation Lookaside Buffer）**。

TLB的实质是cache（不了解cache的朋友可以参考[计算机体系结构-cache高速缓存](https://zhuanlan.zhihu.com/p/482651908)），cache有三种组织方式：直接相连、组相联和全相联。TLB可以用全相联的方式进行组织，全相联能最大化减小页缺失的发生频率，但是全相联电路的性能欠优，难以支持大容量，因此当TLB比较大的时候，可以用组相联的组织方式组织TLB。

TLB保存页表项的副本，因此页表项有的内容它全都要有，另外，**TLB要把虚拟页号保存下来**，这个虚拟页号可以拿来和CPU给的地址做比较，这样可以确保自己真的存有该页表项，而页表则不需要保存虚拟页号，因为页表是顺序存储，虚拟页号的信息已经保存在页表项的顺序表下标中了。

## 8、小结

本文简要谈论了关于在高性能处理器中广泛使用的虚拟存储器的一系列问题，通过阅读本文，读者应当可以建立起对虚拟地址、MMU和虚拟存储器的认识。关于TLB，本文只用了很短的一个章节进行讨论，其实关于TLB的内容可以写很多很多，以后我可能会针对TLB写独立的文章。

## 9、参考资料

\[1\] John L. Hennessy,David A. Patterson.计算机体系结构：量化研究方法（第5版）\[M\]

\[2\] 姚永斌.超标量处理器设计\[M\]

\[3\] 汤小丹,梁红兵,哲凤屏,汤子瀛.现代操作系统\[M\]